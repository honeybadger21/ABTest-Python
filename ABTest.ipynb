{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B Testing in Python \n",
    "\n",
    ">Let's imagine you work on the product team at a <b>medium-sized online e-commerce business</b>. The UX designer worked really hard on <b>a new version of the product page</b>, with the <b>hope</b> that it will lead to a <b>higher conversion rate</b>. The product manager (PM) told you that the current conversion rate is about 13% on average throughout the year, and that the team would be happy with an increase of 2%, meaning that the <b>new design will be considered a success if it raises the conversion rate</b> to 15%.\n",
    "\n",
    "This notebook aims at understanding the process of analysing A/B test, right from formulating a hypothesis, testing it, and finally interpreting the results. \n",
    "\n",
    "<b>References:</b> \n",
    "1. A/B Testing Procedure: https://towardsdatascience.com/ab-testing-with-python-e5964dd66143 \\\n",
    "2. Code Replicated From Here: https://github.com/renatofillinich/ab_test_guide_in_python \\\n",
    "3. Data Source: https://www.kaggle.com/datasets/zhangluyuan/ab-testing?resource=download \n",
    "\n",
    "A dataset from Kaggle (linked above) containing the results of an A/B test on what seems to be 2 different designs of a webpage is used here (old_page vs new_page). \n",
    "\n",
    "<b>Steps illustarted in the notebook:</b>\n",
    "1. Designing our Experiment \n",
    "2. Collection and Preparing the Data\n",
    "3. Visualizing the Results\n",
    "4. Testing the Hypothesis\n",
    "5. Drawing Conclusions \n",
    "\n",
    "We have imagined a more realistic scenario after looking at the data. So now we can perform an A/B test on a subset of the user base before rolling out the change. \n",
    "\n",
    "Before we get started, it's natural to ask the question: <b>What is an A/B Test?</b>\n",
    "\n",
    ">A/B testing (also known as bucket testing, split-run testing, or split testing) is a user experience research methodology. A/B tests consist of a randomized experiment that usually involves two variants (A and B), although the concept can be also extended to multiple variants of the same variable. It includes application of statistical hypothesis testing or \"two-sample hypothesis testing\" as used in the field of statistics. A/B testing is a way to compare multiple versions of a single variable, for example by testing a subject's response to variant A against variant B, and determining which of the variants is more effective. [https://en.wikipedia.org/wiki/A/B_testing] \n",
    "\n",
    "### Step 01: Designing The Experiment \n",
    "<b><u>Formulating a Hypothesis</u></b>\n",
    "\n",
    "Here we don't know if the new design will perform better or worse or the same, so we 'll choose a <b>two-tailed test</b>: \n",
    ">In statistical significance testing, a one-tailed test and a two-tailed test are alternative ways of computing the statistical significance of a parameter inferred from a data set, in terms of a test statistic. A two-tailed test is appropriate if the estimated value is greater or less than a certain range of values, for example, whether a test taker may score above or below a specific range of scores. This method is used for null hypothesis testing and if the estimated value exists in the critical areas, the alternative hypothesis is accepted over the null hypothesis. A one-tailed test is appropriate if the estimated value may depart from the reference value in only one direction, left or right, but not both. [https://en.wikipedia.org/wiki/One-_and_two-tailed_tests]\n",
    "\n",
    "H<sub>0</sub>: p = p<sub>0</sub>\\\n",
    "H<sub>A</sub>: p != p<sub>0</sub>\n",
    "\n",
    "where p, p<sub>0</sub> stand for the conversion rate of the new and old design, respectively. Also, setting the confidence level at 95%. \\\n",
    ">$\\alpha = 0.05$\n",
    "\n",
    "<b><u>Choosing the Variables</u></b>\n",
    "\n",
    "For the test, we think of 2 groups: \n",
    "1. Control: Show the old design\n",
    "2. Treatment: Show the new design\n",
    "\n",
    "With two groups, we can basically control for factors other than the design that might impact our result. \n",
    "\n",
    "Further, understand that we are interested in capturing the conversion rate. We can encode it as a binary variable:\n",
    "1. 0: User did not buy the product during this user session\n",
    "2. 1: User bought the product during this user session\n",
    "\n",
    "This way, we can easily calculate the mean for each group to get the conversion rate of each design. \n",
    "\n",
    "<b><u>Choosing a Sample Size</u></b>\n",
    "\n",
    "We will not test our whole user base (duh!), but only a subset. Thus, the conversion rates obtained here will be <i>estimates</i> of the true rates. \n",
    "\n",
    "The number of people (or user sessions) we decide to capture in each group will have an effect on the precision of our estimated conversion rates: the larger the sample size, the more precise our estimates (i.e. the smaller our confidence intervals), the higher the chance to detect a difference in the two groups, if present. On the other hand, the larger our sample gets, the more expensive (and impractical) our study becomes.\n",
    "\n",
    "So, <b>how to decide the number of people to have in each group? </b>\n",
    ">Power Analysis: A power analysis is the calculation used to estimate the smallest sample size needed for an experiment, given a required significance level, statistical power, and effect size. It helps to determine if a result from an experiment or survey is due to chance, or if it is genuine and significant.\n",
    "\n",
    "Factors:\n",
    "1. Power of the test = $1-\\beta$: This represents the probability of finding a statistical difference between the groups in our test when a difference is actually present. This is usually set at 0.8 as a convention. \n",
    "2. Alpha value = $\\alpha$: Critical value set to 0.05 earlier. \n",
    "3. Effect Size: How big of a difference we expect there to be between the conversion rates. Since our team would be happy with a difference of 2%, we can use 13% and 15% to calculate the effect size we expect.\n",
    "\n",
    "<b>Finally, time for some calculations:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "font = {\n",
    "            'family' : 'Helvetica',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 14\n",
    "       }\n",
    "\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n"
     ]
    }
   ],
   "source": [
    "# Calculating effect size based on our expected rates\n",
    "effect_size = sms.proportion_effectsize(0.13, 0.15)    \n",
    "\n",
    "# Calculating sample size needed\n",
    "required_n = sms.NormalIndPower().solve_power(\n",
    "                                                effect_size, \n",
    "                                                power=0.8, \n",
    "                                                alpha=0.05, \n",
    "                                                ratio=1\n",
    "                                              ) \n",
    "\n",
    "# Rounding up to next whole number                          \n",
    "required_n = ceil(required_n)                         \n",
    "print(required_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need atleast 4720 observations for each group. Also, having set the power parameter to 0.8 in practice means that if there exists an actual difference in conversion rate between our designs, assuming the difference is the one we estimated (13% vs. 15%), we have about 80% chance to detect it as statistically significant in our test with the sample size we calculated.\n",
    "\n",
    "### Step 02: Collecting and Preparing the Data\n",
    "We have the number of observations that we will require. Ideally, this is the stage where an actual experiment is set up and then data is collected through it. But we will be using the Kaggle dataset referenced right at the start of this notebook. To simulate a data collection situation, we will check and clean the data as required, and further randomly sample 4720 rows from it for each group.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import glob\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "files = glob.glob('*.zip')\n",
    "files "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file in files:\n",
    "    print('Unzipping:', file)\n",
    "\n",
    "    with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('Data-Files')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.listdir('Data-Files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data-Files/ab_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# we're only interested in the group and converted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>landing_page</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>1928</td>\n",
       "      <td>145274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>145311</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "landing_page  new_page  old_page\n",
       "group                           \n",
       "control           1928    145274\n",
       "treatment       145311      1965"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make sure all the control group are seeing the old page and viceversa\n",
    "pd.crosstab(df['group'], df['landing_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3894 users that appear multiple times in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Checking in case any user has been sampled multiple times \n",
    "session_counts = df['user_id'].value_counts(ascending = False)\n",
    "multi_users = session_counts[session_counts > 1].count()\n",
    "\n",
    "print(f'There are {multi_users} users that appear multiple times in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 3894 is small compared to total 294478 entries, we can go ahead and drop the multiple enteries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286690, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_drop = session_counts[session_counts>1].index\n",
    "df = df[~df['user_id'].isin(user_drop)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sampling</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_sample = df[df['group'] == 'control'].sample(n = required_n, random_state = 22)\n",
    "treatment_sample = df[df['group'] == 'treatment'].sample(n = required_n, random_state = 22)\n",
    "\n",
    "ab_test = pd.concat([control_sample, treatment_sample], axis=0)\n",
    "ab_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>763854</td>\n",
       "      <td>2017-01-21 03:43:17.188315</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>690555</td>\n",
       "      <td>2017-01-18 06:38:13.079449</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>861520</td>\n",
       "      <td>2017-01-06 21:13:40.044766</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630778</td>\n",
       "      <td>2017-01-05 16:42:36.995204</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>656634</td>\n",
       "      <td>2017-01-04 15:31:21.676130</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9435</th>\n",
       "      <td>908512</td>\n",
       "      <td>2017-01-14 22:02:29.922674</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>873211</td>\n",
       "      <td>2017-01-05 00:57:16.167151</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>631276</td>\n",
       "      <td>2017-01-20 18:56:58.167809</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>662301</td>\n",
       "      <td>2017-01-03 08:10:57.768806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9439</th>\n",
       "      <td>944623</td>\n",
       "      <td>2017-01-19 10:56:01.648653</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "0      763854  2017-01-21 03:43:17.188315    control     old_page          0\n",
       "1      690555  2017-01-18 06:38:13.079449    control     old_page          0\n",
       "2      861520  2017-01-06 21:13:40.044766    control     old_page          0\n",
       "3      630778  2017-01-05 16:42:36.995204    control     old_page          0\n",
       "4      656634  2017-01-04 15:31:21.676130    control     old_page          0\n",
       "...       ...                         ...        ...          ...        ...\n",
       "9435   908512  2017-01-14 22:02:29.922674  treatment     new_page          0\n",
       "9436   873211  2017-01-05 00:57:16.167151  treatment     new_page          0\n",
       "9437   631276  2017-01-20 18:56:58.167809  treatment     new_page          0\n",
       "9438   662301  2017-01-03 08:10:57.768806  treatment     new_page          0\n",
       "9439   944623  2017-01-19 10:56:01.648653  treatment     new_page          1\n",
       "\n",
       "[9440 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9440 entries, 0 to 9439\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   user_id       9440 non-null   int64 \n",
      " 1   timestamp     9440 non-null   object\n",
      " 2   group         9440 non-null   object\n",
      " 3   landing_page  9440 non-null   object\n",
      " 4   converted     9440 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 368.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ab_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control      4720\n",
       "treatment    4720\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_test['group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 03: Getting to the Results\n",
    "Let's first get some basic statistics to get an idea of what our samples look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_73a7b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_73a7b_level0_col0\" class=\"col_heading level0 col0\" >conversion_rate</th>\n",
       "      <th id=\"T_73a7b_level0_col1\" class=\"col_heading level0 col1\" >std_deviation</th>\n",
       "      <th id=\"T_73a7b_level0_col2\" class=\"col_heading level0 col2\" >std_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >group</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_73a7b_level0_row0\" class=\"row_heading level0 row0\" >control</th>\n",
       "      <td id=\"T_73a7b_row0_col0\" class=\"data row0 col0\" >0.123</td>\n",
       "      <td id=\"T_73a7b_row0_col1\" class=\"data row0 col1\" >0.329</td>\n",
       "      <td id=\"T_73a7b_row0_col2\" class=\"data row0 col2\" >0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_73a7b_level0_row1\" class=\"row_heading level0 row1\" >treatment</th>\n",
       "      <td id=\"T_73a7b_row1_col0\" class=\"data row1 col0\" >0.126</td>\n",
       "      <td id=\"T_73a7b_row1_col1\" class=\"data row1 col1\" >0.331</td>\n",
       "      <td id=\"T_73a7b_row1_col2\" class=\"data row1 col2\" >0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb2000b9370>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_rates = ab_test.groupby('group')['converted']\n",
    "\n",
    "# Standard deviation of the proportion\n",
    "std_p = lambda x: np.std(x, ddof = 0)\n",
    "\n",
    "# Standard error of the proportion (std / sqrt(n))\n",
    "se_p = lambda x: stats.sem(x, ddof = 0)\n",
    "\n",
    "conversion_rates = conversion_rates.agg([np.mean, std_p, se_p])\n",
    "conversion_rates.columns = ['conversion_rate', 'std_deviation', 'std_error']\n",
    "\n",
    "conversion_rates.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats above indicate that our designed performed very similary, with the new design performing only slightly better (12.6% over 12.3%).\n",
    "\n",
    "The conversion rates for our groups are indeed very close. Also note that the conversion rate of the control group is lower than what we would have expected given what we knew about our avg. conversion rate (12.3% vs. 13%). This goes to show that there is some variation in results when sampling from a population.\n",
    "\n",
    "<b>Trying out a different sample, just for a quick check:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_63120\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_63120_level0_col0\" class=\"col_heading level0 col0\" >conversion_rate</th>\n",
       "      <th id=\"T_63120_level0_col1\" class=\"col_heading level0 col1\" >std_deviation</th>\n",
       "      <th id=\"T_63120_level0_col2\" class=\"col_heading level0 col2\" >std_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >group</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_63120_level0_row0\" class=\"row_heading level0 row0\" >control</th>\n",
       "      <td id=\"T_63120_row0_col0\" class=\"data row0 col0\" >0.123</td>\n",
       "      <td id=\"T_63120_row0_col1\" class=\"data row0 col1\" >0.329</td>\n",
       "      <td id=\"T_63120_row0_col2\" class=\"data row0 col2\" >0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63120_level0_row1\" class=\"row_heading level0 row1\" >treatment</th>\n",
       "      <td id=\"T_63120_row1_col0\" class=\"data row1 col0\" >0.121</td>\n",
       "      <td id=\"T_63120_row1_col1\" class=\"data row1 col1\" >0.326</td>\n",
       "      <td id=\"T_63120_row1_col2\" class=\"data row1 col2\" >0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb200233a90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_sample2 = df[df['group'] == 'control'].sample(n = required_n, random_state = 10)\n",
    "treatment_sample2 = df[df['group'] == 'treatment'].sample(n = required_n, random_state = 10)\n",
    "\n",
    "ab_test2 = pd.concat([control_sample2, treatment_sample2], axis=0)\n",
    "ab_test2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "conversion_rates2 = ab_test2.groupby('group')['converted']\n",
    "\n",
    "# Standard deviation of the proportion\n",
    "std_p2 = lambda x: np.std(x, ddof = 0)\n",
    "\n",
    "# Standard error of the proportion (std / sqrt(n))\n",
    "se_p2 = lambda x: stats.sem(x, ddof = 0)\n",
    "\n",
    "conversion_rates2 = conversion_rates2.agg([np.mean, std_p, se_p])\n",
    "conversion_rates2.columns = ['conversion_rate', 'std_deviation', 'std_error']\n",
    "\n",
    "conversion_rates2.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually got a lower value, although again it is just slightly lower. \n",
    "\n",
    "We need to check if these differences between control and treatment are <i>statistically significant</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 04: Testing the Hypothesis\n",
    "Since we have a very large sample, we can use the normal approximation for calculating the p-value (viz. z-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z statistic: -0.34\n",
      "p-value: 0.732\n",
      "ci 95% for control group: [0.114, 0.133]\n",
      "ci 95% for treatment group: [0.116, 0.135]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "\n",
    "control_results = ab_test[ab_test['group'] == 'control']['converted']\n",
    "treatment_results = ab_test[ab_test['group'] == 'treatment']['converted']\n",
    "\n",
    "n_con = control_results.count()\n",
    "n_treat = treatment_results.count()\n",
    "\n",
    "successes = [control_results.sum(), treatment_results.sum()]\n",
    "nobs = [n_con, n_treat]\n",
    "\n",
    "z_stat, pval = proportions_ztest(successes, nobs = nobs)\n",
    "(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n",
    "\n",
    "print(f'z statistic: {z_stat:.2f}')\n",
    "print(f'p-value: {pval:.3f}')\n",
    "print(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\n",
    "print(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We got a p-value = 0.732 which is way above our $\\alpha = 0.05$, we CANNOT reject the null hypothesis H<sub>0</sub>, which means that our <b><i>new design DID NOT perform significantly different than the old one</i></b>. \n",
    "\n",
    "Additionally, looking at the confidence interval for the treatment group: [0.116, 0.135], we notice that:\n",
    "1. It includes the baseline value 13%\n",
    "2. But it does not include the target value 15% (the +2% that was aimed for)\n",
    "\n",
    "What this means is that it is more likely that the true conversion rate of the new design is similar to our baseline, rather than the 15% target we had hoped for. This is further proof that our new design is not likely to be an improvement on our old design, and that unfortunately we are back to the drawing board!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>The End</i></b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
